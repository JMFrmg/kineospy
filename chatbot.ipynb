{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download fr_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2d751zobXmQ",
        "outputId": "f323088d-b694-49f8-9f6c-b4e493287788"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr_core_news_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-2.2.5/fr_core_news_md-2.2.5.tar.gz (88.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 88.6 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_md==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tBUxDZvEZCaW"
      },
      "outputs": [],
      "source": [
        "# import en_core_web_lg # Large SpaCy model for English language\n",
        "import numpy as np\n",
        "import re # regular expressions\n",
        "import spacy # NLU library\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.svm import SVC # Support Vector Classification model\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.cli.download(\"fr_core_news_md\")\n",
        "nlp = spacy.load('fr_core_news_md')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ndlJWePcGZn",
        "outputId": "e68a1c9d-0d76-453a-902f-a2080d7cd0d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop_words=set(STOP_WORDS)\n",
        "\n",
        "# deselect_stop_words = ['n\\'', 'ne','pas','plus','personne','aucun','ni','aucune','rien']\n",
        "# for w in deselect_stop_words:\n",
        "#     if w in stop_words:\n",
        "#         stop_words.remove(w)\n",
        "#     else:\n",
        "#         continue"
      ],
      "metadata": {
        "id": "ch6QQy50mCYu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data\n",
        "training_sentences = [\n",
        "    \"Je ne me sens pas bien\",\n",
        "    \"Je ne suis pas bien\",\n",
        "    \"Je ne peux plus supporter la situation\",\n",
        "    \"Je vais mal\",\n",
        "    \"Je suis triste\",\n",
        "    \"Je ne me sens pas très bien\",\n",
        "    \"Je vais très mal\",\n",
        "    \"Je suis désespéré\",\n",
        "    \"Je me sens bien\",\n",
        "    \"Je vais bien\", \n",
        "    \"Je suis heureux\",\n",
        "    \"Je suis en forme\",\n",
        "    \"Je me sens plutôt bien\",\n",
        "    \"Bien\",\n",
        "    \n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "training_intents = [\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"negatif\",\n",
        "    \"positif\",\n",
        "    \"positif\",\n",
        "    \"positif\",\n",
        "    \"positif\",\n",
        "    \"positif\",\n",
        "    \"positif\",\n",
        "]"
      ],
      "metadata": {
        "id": "aZv1xQFOaQ0J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the array with zeros: X\n",
        "X_train = np.zeros((len(training_sentences), \n",
        "              nlp('sentences').vocab.vectors_length))\n",
        "\n",
        "for i, sentence in enumerate(training_sentences):\n",
        "    # Pass each each sentence to the nlp object to create a document\n",
        "    doc = nlp(sentence)\n",
        "    # Save the document's .vector attribute to the corresponding row in X\n",
        "    X_train[i, :] = doc.vector"
      ],
      "metadata": {
        "id": "Z9isvpeTZLKW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a support vector classifier\n",
        "clf = SVC(C=1, gamma=\"auto\", probability=True)\n",
        "\n",
        "# Fit the classifier using the training data\n",
        "clf.fit(X_train, training_intents)\n",
        "\n",
        "#Yes, a lot can be done here to check / improve model performance! We will leave that for another day!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1voZX7c-ZDRA",
        "outputId": "b68c3ea1-9cd2-425d-e6d6-388591108daf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, gamma='auto', probability=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_intent_ml(text):\n",
        "    doc = nlp(text)\n",
        "    return(clf.predict([doc.vector])[0])"
      ],
      "metadata": {
        "id": "qgZEu_gfZDSi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_format = \"IN: {input}\\nOUT: {output}\\n\" + \"_\"*50"
      ],
      "metadata": {
        "id": "CPlQxrB-do9r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses_ml = {\n",
        "    \"negatif\":\"Je suis désolée d'entendre ça.\",\n",
        "    \"positif\": \"Super! Te sens tu en forme pour un peu de sport?\",\n",
        "    \"default\":\"Je t'aime aussi!\"\n",
        "}\n",
        "\n",
        "def respond_ml(text):\n",
        "    response = responses_ml.get(get_intent_ml(text), responses_ml[\"default\"])\n",
        "    return(output_format.format(input=text, output=response))"
      ],
      "metadata": {
        "id": "g1ntWAHTZDT7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(respond_ml(\"Je ne me sens pas bien\"))\n",
        "print(respond_ml(\"Je vais bien\"))\n",
        "print(respond_ml(\"l\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j5alW4Jc9hR",
        "outputId": "8ab5bc23-e2e4-4425-ee76-3eb0c142c54d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN: Je ne me sens pas bien\n",
            "OUT: Je suis désolée d'entendre ça.\n",
            "__________________________________________________\n",
            "IN: Je vais bien\n",
            "OUT: Je suis désolée d'entendre ça.\n",
            "__________________________________________________\n",
            "IN: l\n",
            "OUT: Je suis désolée d'entendre ça.\n",
            "__________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MQ-iPgZdc9jJ"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}